{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNtXbKpoZHi+oppRWzq38MA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"i1vS-JZ_I5yS","executionInfo":{"status":"error","timestamp":1695225704169,"user_tz":-180,"elapsed":2888586,"user":{"displayName":"Teddy Ryswelt","userId":"03491859125458221030"}},"outputId":"ab5c1ed3-e844-4aed-ef82-fcc1cc5db79c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n","  warnings.warn(\n","Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['gitpython>=3.1.30'] not found, attempting AutoUpdate...\n","Collecting gitpython>=3.1.30\n","  Downloading GitPython-3.1.36-py3-none-any.whl (189 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 189.5/189.5 kB 4.2 MB/s eta 0:00:00\n","Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 62.7/62.7 kB 12.4 MB/s eta 0:00:00\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, gitdb, gitpython\n","Successfully installed gitdb-4.0.10 gitpython-3.1.36 smmap-5.0.1\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 5.5s, installed 1 package: ['gitpython>=3.1.30']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","YOLOv5 üöÄ 2023-9-20 Python-3.10.12 torch-2.0.1+cu118 CPU\n","\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-67ca225f634b>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏—è –∫–ª–∞–≤–∏—à–∏\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import requests\n","import cv2\n","import numpy as np\n","import torch\n","\n","# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YOLOv5s\n","model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", pretrained=False)\n","\n","# –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ –ø–æ —Å—Å—ã–ª–∫–µ\n","url = \"https://www.vidsplay.com/atv-road-aerial/video.mp4\"\n","response = requests.get(url)\n","\n","# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ —Ñ–∞–π–ª\n","with open(\"video.mp4\", \"wb\") as f:\n","    f.write(response.content)\n","\n","# –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ –∏–∑ —Ñ–∞–π–ª–∞\n","video = cv2.VideoCapture(\"video.mp4\")\n","\n","# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤–∏–¥–µ–æ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n","frame_width = int(video.get(3))\n","frame_height = int(video.get(4))\n","output_video = cv2.VideoWriter(\"D:/–Ω–æ–≤–∞—è –ø–∞–ø–∫–∞/output_video.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), 30, (frame_width, frame_height))\n","# –ù–æ–≤–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –∫–∞–¥—Ä–æ–≤\n","new_width = 640\n","new_height = 640\n","\n","# –¶–∏–∫–ª –ø–æ –∫–∞–¥—Ä–∞–º –≤–∏–¥–µ–æ\n","while True:\n","    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–∞ –∏–∑ –≤–∏–¥–µ–æ\n","    _, frame = video.read()\n","    # –ü—Ä–æ–≤–µ—Ä–∫–∞, –ø—É—Å—Ç–æ –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n","    if frame is not None:\n","        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è YOLOv5\n","        frame = cv2.resize(frame, (640, 640))\n","        frame = frame.astype(np.float32)\n","\n","        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤\n","        detections = model(frame.unsqueeze(0))\n","\n","        # –í—ã–≤–æ–¥ –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\n","        print(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤:\", len(detections))\n","\n","        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è\n","        for detection in detections:\n","            if detection[\"category_id\"] in [1, 2, 3, 4, 5]:\n","                x, y, w, h = detection[\"bbox\"]\n","                center_x = int(x + w / 2)\n","                center_y = int(y + h / 2)\n","                dx = center_x - frame_width // 2\n","                dy = center_y - frame_height // 2\n","\n","                # –†–∏—Å–æ–≤–∞–Ω–∏–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞ –≤–æ–∫—Ä—É–≥ –æ–±—ä–µ–∫—Ç–∞\n","                cv2.rectangle(frame, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 0), 2)\n","\n","                # –†–∏—Å–æ–≤–∞–Ω–∏–µ –∫—Ä–µ—Å—Ç–∞ –≤ —Ü–µ–Ω—Ç—Ä–µ –æ–±—ä–µ–∫—Ç–∞\n","                cv2.line(frame, (center_x, center_y - 10), (center_x, center_y + 10), (0, 0, 255), 2)\n","                cv2.line(frame, (center_x - 10, center_y), (center_x + 10, center_y), (0, 0, 255), 2)\n","\n","                # –í—ã–≤–æ–¥ —Å–º–µ—â–µ–Ω–∏—è –Ω–∞ —ç–∫—Ä–∞–Ω\n","                cv2.putText(frame, f\"dX: {dx}, dY: {dy}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n","\n","        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–¥—Ä–∞ –Ω–∞ —ç–∫—Ä–∞–Ω\n","        cv2.imshow(\"frame\", frame)\n","\n","        # –ó–∞–ø–∏—Å—å –∫–∞–¥—Ä–∞ –≤ –≤—ã—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ\n","        output_video.write(frame)\n","\n","    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏—è –∫–ª–∞–≤–∏—à–∏\n","    key = cv2.waitKey(1)\n","    if key == 27:\n","        break\n","\n","# –ó–∞–∫—Ä—ã—Ç–∏–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤ –∏ –æ–∫–æ–Ω\n","video.release()\n","output_video.release()\n","cv2.destroyAllWindows()\n"]}]}